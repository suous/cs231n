{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef80b09-9106-4efe-83bd-84f064d5f23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from utils import load_cifar10, batch_plot, seed_everything, accuracy\n",
    "from nn import Linear, ReLU, SGD, Sequential, CrossEntropy\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "np.set_printoptions(precision=3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59caf3-6187-4ecb-a4df-8c4a1d812d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_cifar10(\"../code/cs231n/datasets/cifar-10-batches-py/\")\n",
    "\n",
    "assert X_train.shape == (50000, 32, 32, 3)\n",
    "assert y_train.shape == (50000,)\n",
    "assert X_test.shape == (10000, 32, 32, 3)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea53d4-182f-44f1-9245-1c98eb67c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_valid = int(len(X_train) * 0.2)\n",
    "X_valid, y_valid = X_train[-num_valid:], y_train[-num_valid:]\n",
    "X_train, y_train = X_train[:-num_valid], y_train[:-num_valid]\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_valid: {X_valid.shape}, y_valid: {y_valid.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "plt.bar(*np.unique(y_train, return_counts=True))\n",
    "plt.bar(*np.unique(y_valid, return_counts=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f947aa1-16d2-4205-b769-8f5ca77ad8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indexes of 'batch_size' random digits\n",
    "batch_size = 16\n",
    "random_indexes = np.random.randint(X_train.shape[0], size=batch_size)\n",
    "# Plot digits with labels\n",
    "batch_plot(X_train[random_indexes], y_train[random_indexes], with_border=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a54a9-b56a-4afb-a701-3dd1e1ffdb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train.astype(float) - mean_image).reshape((X_train.shape[0], -1))\n",
    "X_valid = (X_valid.astype(float) - mean_image).reshape((X_valid.shape[0], -1))\n",
    "X_test = (X_test.astype(float) - mean_image).reshape((X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "num_train = 50\n",
    "X_train_samples = X_train[:num_train]\n",
    "y_train_samples = y_train[:num_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378ce7d-7040-4749-832f-66329563ea06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_train_accuracies(\n",
    "    layers=3,\n",
    "    learning_rates=None,\n",
    "    weight_scales=None,\n",
    "    hidden_units=100,\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    plot=True,\n",
    "    save_fig=False,\n",
    "):\n",
    "    (m, n), num_classes = X_train.shape, y_train.max() + 1\n",
    "\n",
    "    if learning_rates is None:\n",
    "        learning_rates = np.asarray(list(reversed(np.logspace(-6, -1, 10))))\n",
    "\n",
    "    if weight_scales is None:\n",
    "        weight_scales = np.logspace(-5, 2, 10)\n",
    "\n",
    "    loss = CrossEntropy()\n",
    "    accuracies = np.zeros((len(learning_rates), len(weight_scales)))\n",
    "    for (lr, scale), (i, j) in zip(\n",
    "        itertools.product(learning_rates, weight_scales),\n",
    "        itertools.product(range(len(learning_rates)), range(len(weight_scales))),\n",
    "    ):\n",
    "        model = Sequential(\n",
    "            [Linear(n, hidden_units, weight_scale=scale), ReLU()]\n",
    "            + [Linear(hidden_units, hidden_units, weight_scale=scale), ReLU()] * (layers - 1)\n",
    "            + [Linear(hidden_units, num_classes, weight_scale=scale)]\n",
    "        )\n",
    "\n",
    "        optimizer = SGD(params=model.parameters, learning_rate=lr)\n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        model.fit(\n",
    "            X_train_samples, y_train_samples, epochs=epochs, store_weights=False, batch_size=batch_size, verbose=False\n",
    "        )\n",
    "\n",
    "        train_samples_preds = np.argmax(model.predict(X_train_samples), axis=1)\n",
    "        train_accuracy = accuracy(y_train_samples, train_samples_preds)\n",
    "        accuracies[i, j] = train_accuracy\n",
    "\n",
    "    if plot is True:\n",
    "        yticks = list(range(0, len(learning_rates), 3))\n",
    "        xticks = list(range(0, len(weight_scales), 3))\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        pos = ax.imshow(accuracies, cmap=plt.cm.gray_r, vmin=0, vmax=100, interpolation=\"none\")\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_xticklabels([f\"{s:.1e}\" for s in weight_scales[xticks]])\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.set_yticklabels([f\"{s:.1e}\" for s in learning_rates[yticks]])\n",
    "        ax.set_xlabel(\"weight scales\")\n",
    "        ax.set_ylabel(\"learning rates\")\n",
    "        ax.set_title(f\"{layers} layers nn accuracies\")\n",
    "        fig.colorbar(pos, ax=ax, fraction=0.019, pad=0.02, aspect=50)\n",
    "        if save_fig is True:\n",
    "            plt.savefig(f\"../code/cs231n/notebook_images/{layers}_layers_nn_accuracies.png\", dpi=400, transparent=True)\n",
    "        plt.show()\n",
    "    return accuracies, learning_rates, weight_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9da75-2c87-4065-bd20-398ddf33aeae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rates = np.asarray(list(reversed(np.logspace(-6, -1, 32))))\n",
    "weight_scales = np.logspace(-5, 2, 32)\n",
    "\n",
    "for layers in range(2, 6):\n",
    "    search_train_accuracies(layers=layers, learning_rates=learning_rates, weight_scales=weight_scales, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1ebd1-2fab-43a9-bcd3-f1df05ad5fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_weights(\n",
    "    layers=3,\n",
    "    learning_rate=5e-3,\n",
    "    weight_scale=5e-2,\n",
    "    hidden_units=100,\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    weight_layer=1,\n",
    "    subsample_steps=1,\n",
    "    verbose=False,\n",
    "):\n",
    "    (m, n), num_classes = X_train.shape, y_train.max() + 1\n",
    "    model = Sequential(\n",
    "        [Linear(n, hidden_units, weight_scale=weight_scale), ReLU()]\n",
    "        + [Linear(hidden_units, hidden_units, weight_scale=weight_scale), ReLU()] * (layers - 1)\n",
    "        + [Linear(hidden_units, num_classes, weight_scale=weight_scale)]\n",
    "    )\n",
    "\n",
    "    optimizer = SGD(params=model.parameters, learning_rate=learning_rate)\n",
    "    loss = CrossEntropy()\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    history = model.fit(\n",
    "        X_train_samples, y_train_samples, epochs=epochs, store_weights=True, batch_size=batch_size, verbose=verbose\n",
    "    )\n",
    "\n",
    "    train_samples_preds = np.argmax(model.predict(X_train_samples), axis=1)\n",
    "    print(f\"train acc: {accuracy(y_train_samples, train_samples_preds)}\")\n",
    "\n",
    "    total_layer_weights = [np.asarray([w[l].value for w in history[\"weights\"]]) for l in range(layers)]\n",
    "    total_layer_grads = [np.asarray([w[l].grad for w in history[\"weights\"]]) for l in range(layers)]\n",
    "\n",
    "    layers_weights = list(total_layer_weights[weight_layer].reshape((epochs, -1))[::subsample_steps])\n",
    "    layers_grads = list(total_layer_grads[weight_layer].reshape((epochs, -1))[::subsample_steps])\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "    axs[0].violinplot(layers_weights, showmeans=True, showmedians=True)\n",
    "    axs[0].set_title(\"weights\")\n",
    "    axs[1].violinplot(layers_grads, showmeans=True, showmedians=True)\n",
    "    axs[1].set_title(\"gradients\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.yaxis.grid(True)\n",
    "        ax.set_xticks(\n",
    "            [y + 1 for y in range(len(layers_weights))],\n",
    "            labels=[i * subsample_steps for i in range(len(layers_weights))],\n",
    "        )\n",
    "    plt.show()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a94960-64de-4a51-b596-b10278afd7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_weights(layers=2, weight_scale=5e-2, learning_rate=1e-3, epochs=20, subsample_steps=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
