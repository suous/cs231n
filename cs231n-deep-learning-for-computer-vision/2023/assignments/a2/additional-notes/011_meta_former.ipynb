{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![MetaFormer](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*djedJeSMHNiRDE8FDq4Y-Q.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64d6e9b88646aeea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from utils import seed_everything, batch_plot, train_part_challenge, check_accuracy_part34\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything()\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058214a28a6c4a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, patch_size, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=out_channels, kernel_size=patch_size, stride=patch_size, padding=0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, channels, expansion_factor, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        expanded_channels = int(expansion_factor * channels)\n",
    "        self.fc1 = nn.Conv2d(channels, expanded_channels, 1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc2 = nn.Conv2d(expanded_channels, channels, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelLayerNorm(nn.LayerNorm):\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super().__init__(num_channels, **kwargs)\n",
    "        self.bias = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (batch_size, channels, image_size, image_size)\n",
    "        x = x.permute(0, 2, 3, 1)  # (batch_size, image_size, image_size, channels)\n",
    "        x = super().forward(x)  # (batch_size, image_size, image_size, channels)\n",
    "        x = x.permute(0, 3, 1, 2)  # (batch_size, channels, image_size, image_size)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNormAct(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        groups=1,\n",
    "        bias=False,\n",
    "        dropout_rate=0.0,\n",
    "        norm=nn.BatchNorm2d,\n",
    "        activation=nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0.0 else nn.Identity()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.norm = norm(out_channels) if norm is not None else nn.Identity()\n",
    "        self.act = activation() if activation is not None else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# MobileNetV2: https://arxiv.org/abs/1801.04381\n",
    "class DepthSeparableConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        expansion_factor=2,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "        stride=1,\n",
    "        bias=False,\n",
    "        dropout_rate=0.0,\n",
    "        norm=nn.BatchNorm2d,\n",
    "        activation=nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        expanded_channels = int(expansion_factor * in_channels)\n",
    "        self.point_wise_expander = (\n",
    "            ConvNormAct(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=expanded_channels,\n",
    "                kernel_size=1,\n",
    "                bias=bias,\n",
    "                norm=norm,\n",
    "                activation=activation,\n",
    "                dropout_rate=dropout_rate,\n",
    "            )\n",
    "            if in_channels != expanded_channels\n",
    "            else nn.Identity()\n",
    "        )\n",
    "        self.depth_with_conv = ConvNormAct(\n",
    "            in_channels=expanded_channels,\n",
    "            out_channels=expanded_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            groups=expanded_channels,\n",
    "            bias=bias,\n",
    "            norm=norm,\n",
    "            activation=activation,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.point_wise_compressor = ConvNormAct(\n",
    "            in_channels=expanded_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            bias=bias,\n",
    "            norm=norm,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.point_wise_expander(x)\n",
    "        x = self.depth_with_conv(x)\n",
    "        x = self.point_wise_compressor(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MetaFormerBlock(nn.Module):\n",
    "    def __init__(self, channels, expansion_factor, dropout_rate=0.0, kernel_size=3, norm=nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm(channels)\n",
    "        self.token_mixer = DepthSeparableConv(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            expansion_factor=expansion_factor,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            dropout_rate=dropout_rate,\n",
    "            norm=norm,\n",
    "        )\n",
    "        self.norm2 = norm(channels)\n",
    "        self.mlp2 = MLPBlock(channels, expansion_factor, dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (batch_size, channels, image_size, image_size)\n",
    "        x = x + self.token_mixer(self.norm1(x))\n",
    "        x = x + self.mlp2(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class MetaFormerStage(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        expansion_factor,\n",
    "        num_blocks,\n",
    "        dropout_rate=0.0,\n",
    "        kernel_size=3,\n",
    "        down_sample=True,\n",
    "        norm=nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.down_sampler = (\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            if down_sample\n",
    "            else nn.Identity()\n",
    "        )\n",
    "        self.mixer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                MetaFormerBlock(\n",
    "                    channels=out_channels,\n",
    "                    expansion_factor=expansion_factor,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    kernel_size=kernel_size,\n",
    "                    norm=norm,\n",
    "                )\n",
    "                for _ in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down_sampler(x)\n",
    "        for mixer_block in self.mixer_blocks:\n",
    "            x = mixer_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# https://arxiv.org/abs/2111.11418\n",
    "# https://arxiv.org/abs/2210.13452\n",
    "class MetaFormer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size,\n",
    "        hidden=64,\n",
    "        expansion_factors=None,\n",
    "        dropout_rates=None,\n",
    "        num_blocks=None,\n",
    "        num_classes=10,\n",
    "        kernel_size=3,\n",
    "        num_layers=2,\n",
    "        down_sample=True,\n",
    "        use_head=True,\n",
    "        norm=nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if expansion_factors is None:\n",
    "            expansion_factors = [2] * num_layers\n",
    "        if dropout_rates is None:\n",
    "            dropout_rates = [0.0] * num_layers\n",
    "        if num_blocks is None:\n",
    "            num_blocks = [2] * num_layers\n",
    "        self.patch_embedding = PatchEmbedding(patch_size, in_channels=3, out_channels=hidden)\n",
    "\n",
    "        down_sample_factor = 1 + int(down_sample)\n",
    "        self.stacks = nn.ModuleList(\n",
    "            [\n",
    "                MetaFormerStage(\n",
    "                    in_channels=hidden * down_sample_factor ** (max(0, i - 1)),\n",
    "                    out_channels=hidden * down_sample_factor**i,\n",
    "                    expansion_factor=expansion_factors[i],\n",
    "                    num_blocks=num_blocks[i],\n",
    "                    dropout_rate=dropout_rates[i],\n",
    "                    kernel_size=kernel_size,\n",
    "                    down_sample=down_sample and i > 0,\n",
    "                    norm=norm,\n",
    "                )\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        expanded = down_sample_factor ** (num_layers - 1)\n",
    "        head = hidden if use_head else hidden * expanded\n",
    "        self.norm = norm(hidden * expanded)\n",
    "        self.down = nn.Linear(hidden * expanded, hidden) if use_head else nn.Identity()\n",
    "        self.fc = nn.Linear(head, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        for stack in self.stacks:\n",
    "            x = stack(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=[2, 3])\n",
    "        x = self.down(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d39b166302549d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = 49000\n",
    "data_path = \"../code/cs231n/datasets\"\n",
    "\n",
    "transform_train = T.Compose(\n",
    "    [T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    ")\n",
    "\n",
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "cifar10_train = dset.CIFAR10(data_path, train=True, download=True, transform=transform_train)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "cifra10_visualize = dset.CIFAR10(data_path, train=True, download=True, transform=T.ToTensor())\n",
    "loader_visualize = DataLoader(\n",
    "    cifra10_visualize, batch_size=16, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000))\n",
    ")\n",
    "\n",
    "images, labels = next(iter(loader_visualize))\n",
    "batch_plot(images.permute(0, 2, 3, 1).numpy(), labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee91e1da9a57043",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "log_dir = Path(data_path).joinpath(\"runs\")\n",
    "\n",
    "model = MetaFormer(\n",
    "    patch_size=4,\n",
    "    hidden=128,\n",
    "    num_layers=2,\n",
    "    expansion_factors=[3, 2],\n",
    "    dropout_rates=[0.1, 0.2],\n",
    "    num_blocks=[3, 2],\n",
    "    num_classes=10,\n",
    "    kernel_size=3,\n",
    "    use_head=True,\n",
    "    down_sample=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epoch)\n",
    "\n",
    "check_point_name = train_part_challenge(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epoch,\n",
    "    device=device,\n",
    "    train_loader=loader_train,\n",
    "    valid_loader=loader_val,\n",
    "    log_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68545f6bb5a3228",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(check_point_name)\n",
    "print(\n",
    "    f\"best model with train accuracy: {checkpoint['train_accuracy']:.2f} and valid accuracy {checkpoint['valid_accuracy']:.2f}\"\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "check_accuracy_part34(loader_test, model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/training_process_conformer.png\">\n",
    "\n",
    "```\n",
    "best model with train accuracy: 90.23 and valid accuracy 84.80\n",
    "Checking accuracy on test set\n",
    "Got 8240 / 10000 correct (82.40)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T04:35:56.272394Z",
     "start_time": "2023-09-27T04:35:56.271419Z"
    }
   },
   "id": "f4593ce5f35e8cc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
