{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33b33f-6dc0-4bac-a556-465f2d46a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "from utils import batch_plot\n",
    "from conv import load_sample_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad06372-f82f-42b0-8340-fc4eacbcc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = np.asarray(load_sample_images().images)\n",
    "sample_images = sample_images / sample_images.max()\n",
    "\n",
    "# for better plot\n",
    "n = 420\n",
    "sample_images = sample_images[:, :n, :n, :]\n",
    "\n",
    "batch_plot(sample_images, with_border=False, imgsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd5441-a382-4add-a925-6fded4fe1d52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate sliding window views of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c29dc-1af7-4486-a2c6-59eefb51e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using numpy sliding_window_view: stride=1\n",
    "batch, height, width, channel, window, stride, filters = 4, 7, 7, 3, 3, 1, 1\n",
    "x = np.arange(batch * height * width * channel).reshape((batch, height, width, channel))\n",
    "y = np.lib.stride_tricks.sliding_window_view(x, window_shape=(filters, window, window, channel)).squeeze(axis=(3, 4))\n",
    "\n",
    "# (height - window)/stride + 1 = chunk_height\n",
    "chunk_height, chunk_width = (height - window) // stride + 1, (width - window) // stride + 1\n",
    "assert y.shape == (batch, chunk_height, chunk_width, window, window, channel)\n",
    "\n",
    "# # low level operation\n",
    "stride = 1\n",
    "stride_batch, stride_height, stride_width, stride_channel = x.strides\n",
    "z = np.lib.stride_tricks.as_strided(\n",
    "    x,\n",
    "    shape=(batch, chunk_height, chunk_width, window, window, channel),\n",
    "    strides=(\n",
    "        stride_batch,\n",
    "        stride * stride_height,\n",
    "        stride * stride_width,\n",
    "        stride_height,\n",
    "        stride_width,\n",
    "        stride_channel,\n",
    "    ),\n",
    ")\n",
    "assert np.allclose(y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf9b28-fe90-48e9-9006-ae2e06b63b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot nxn views of the image\n",
    "n = 4\n",
    "batch, height, width, channel = sample_images.shape\n",
    "num_stride_height, num_stride_width = height // n, width // n\n",
    "chunk_height, chunk_width = n, n\n",
    "stride_batch, stride_height, stride_width, stride_channel = sample_images.strides\n",
    "# (height - filter_height)/stride + 1 = chunk_height\n",
    "filter_height, filter_width = height - num_stride_height * (chunk_height - 1), width - num_stride_width * (\n",
    "    chunk_width - 1\n",
    ")\n",
    "chunks = np.lib.stride_tricks.as_strided(\n",
    "    sample_images,\n",
    "    shape=(batch, chunk_height, chunk_width, filter_height, filter_width, channel),\n",
    "    strides=(\n",
    "        stride_batch,\n",
    "        num_stride_height * stride_height,\n",
    "        num_stride_width * stride_width,\n",
    "        stride_height,\n",
    "        stride_width,\n",
    "        stride_channel,\n",
    "    ),\n",
    ")\n",
    "assert chunks.shape == (\n",
    "    batch,\n",
    "    chunk_height,\n",
    "    chunk_width,\n",
    "    filter_height,\n",
    "    filter_width,\n",
    "    channel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b255f2a-3ae8-4957-8a0a-4b89c64ff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_sample_images = chunks.reshape((batch, -1, filter_height, filter_width, channel))\n",
    "assert sliding_sample_images.shape == (\n",
    "    batch,\n",
    "    chunk_height * chunk_width,\n",
    "    filter_height,\n",
    "    filter_width,\n",
    "    channel,\n",
    ")\n",
    "for sliding_sample_image in sliding_sample_images:\n",
    "    batch_plot(\n",
    "        sliding_sample_image,\n",
    "        with_border=False,\n",
    "        cmap=plt.cm.gray,\n",
    "        tight_layout=None,\n",
    "        wspace=0.01,\n",
    "        hspace=0.01,\n",
    "        imgsize=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d70b6-83c3-4668-ae9e-8f2f8559116c",
   "metadata": {},
   "source": [
    "# Apply filters to the sliding window chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca654e7-4d2b-4f6f-b92c-130407695d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_height = filter_width = 7\n",
    "sample_filters = load_sample_filters(size=filter_height, sigma=1, channel=channel)\n",
    "\n",
    "batch_plot(\n",
    "    list(sample_filters.values()),\n",
    "    list(sample_filters.keys()),\n",
    "    with_border=True,\n",
    "    tight_layout=None,\n",
    "    wspace=0.1,\n",
    "    hspace=0.1,\n",
    "    imgsize=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0322b-b0de-47b2-9716-d0ed6ceb8dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chunked with stride of 1\n",
    "batch, height, width, channel = sample_images.shape\n",
    "filters = np.asarray(list(sample_filters.values()))\n",
    "chunks = np.lib.stride_tricks.sliding_window_view(\n",
    "    sample_images, window_shape=(1, filter_height, filter_width, channel)\n",
    ").squeeze(axis=(3, 4))\n",
    "chunk_height, chunk_width = height - filter_height + 1, width - filter_width + 1\n",
    "assert chunks.shape == (\n",
    "    batch,\n",
    "    chunk_height,\n",
    "    chunk_width,\n",
    "    filter_height,\n",
    "    filter_width,\n",
    "    channel,\n",
    ")\n",
    "\n",
    "# chunks:                                                      (batch, chunk_height, chunk_width, filter_height, filter_width, channel)\n",
    "# filters:                                                     (num_filters, filter_height, filter_width, channel)\n",
    "\n",
    "# 1. step by step\n",
    "# np.expand_dims(chunks, 3):                                   (batch, chunk_height, chunk_width, 1, filter_height, filter_width, channel)\n",
    "# np.expand_dims(chunks, 3) * filters:                         (batch, chunk_height, chunk_width, num_filters, filter_height, filter_width, channel)\n",
    "# np.expand_dims(chunks, 3) * filters).sum(axis=(-3,-2,-1)):   (batch, chunk_height, chunk_width, num_filters, channel)\n",
    "# filtered_sample_images = (np.expand_dims(chunks, 3) * filters).sum(axis=(-3,-2,-1)).transpose((0,3,1,2))\n",
    "# 2. tensordot\n",
    "# filtered_sample_image = np.tensordot(chunks, filters, axes=((3,4,5), (1,2,3))).transpose((0,3,1,2))\n",
    "# 3. einsum\n",
    "# filtered_sample_images = np.einsum('mijklc,nklc->mnij',chunks,filters)\n",
    "\n",
    "# 4. img2col\n",
    "# filters.reshape((-1, filter_height*filter_width*channel)).T                                 (filter_height*filter_width*channel, num_filters)\n",
    "# chunks.reshape((batch*chunk_height*chunk_width, filter_height*filter_width*channel))        (batch*chunk_height*chunk_width*channel, filter_height*filter_width*channel)\n",
    "filtered_sample_images = (\n",
    "    chunks.reshape((batch * chunk_height * chunk_width, filter_height * filter_width * channel))\n",
    "    @ filters.reshape((-1, filter_height * filter_width * channel)).T\n",
    ")\n",
    "filtered_sample_images = filtered_sample_images.reshape((batch, chunk_height, chunk_width, -1)).transpose((0, 3, 1, 2))\n",
    "\n",
    "assert filtered_sample_images.shape == (batch, len(filters), chunk_height, chunk_width)\n",
    "\n",
    "for filtered_sample_image in filtered_sample_images:\n",
    "    batch_plot(\n",
    "        filtered_sample_image,\n",
    "        list(sample_filters.keys()),\n",
    "        with_border=False,\n",
    "        cmap=plt.cm.gray,\n",
    "        tight_layout=None,\n",
    "        wspace=0.1,\n",
    "        hspace=0.1,\n",
    "        imgsize=6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79d582-f65f-4af5-81ae-d83d71005cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "\n",
    "def conv2d(images, kernels):\n",
    "    _, kernel_height, kernel_width, kernel_channel = kernels.shape\n",
    "    padding_height, padding_width = (kernel_height - 1) // 2, (kernel_width - 1) // 2\n",
    "    # same padding\n",
    "    images = np.pad(\n",
    "        images, pad_width=((0, 0), (padding_height, padding_width), (padding_height, padding_width), (0, 0))\n",
    "    )\n",
    "    chunks = np.lib.stride_tricks.sliding_window_view(\n",
    "        images, window_shape=(1, kernel_height, kernel_width, kernel_channel)\n",
    "    ).squeeze(axis=(3, 4))\n",
    "    return np.einsum(\"mijklc,nklc->mnij\", chunks, kernels)\n",
    "\n",
    "\n",
    "def fft_conv2d(images, kernels):\n",
    "    batch_size, image_height, image_width, channel = images.shape\n",
    "    res = np.zeros((batch_size, len(filters), image_height, image_width))\n",
    "\n",
    "    # (num_kernels, 1, kernel_height, kernel_width, channel)\n",
    "    kernels = np.expand_dims(np.rot90(kernels, k=2, axes=(1, 2)), axis=1)\n",
    "\n",
    "    for i, k in enumerate(kernels):\n",
    "        for c in range(channel):\n",
    "            res[:, i, :, :] += signal.fftconvolve(images[..., c], k[..., c], mode=\"same\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166497e-19a0-477a-8a39-2d1925df81a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_filters = np.random.uniform(size=filters.shape)\n",
    "\n",
    "assert np.allclose(conv2d(sample_images, filters), fft_conv2d(sample_images, filters))\n",
    "assert np.allclose(conv2d(sample_images, random_filters), fft_conv2d(sample_images, random_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312722f-473c-4720-9222-30de2f81e76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit conv2d(sample_images, filters)\n",
    "%timeit fft_conv2d(sample_images, np.rot90(filters, k=2, axes=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8284068-3079-4221-9e85-12b69768680f",
   "metadata": {},
   "source": [
    "- [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
